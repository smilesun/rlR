<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Define custom environment for deep reinforcement learn â€¢ rlR</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Define custom environment for deep reinforcement learn">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">rlR</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.1.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-file-text-o"></span>
     
    Topics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/define_custom_environments.html">Specify Custom Environment</a>
    </li>
    <li>
      <a href="../articles/repeated_experiment.html">Repeated Experiment</a>
    </li>
    <li>
      <a href="../articles/customized_brain_mountainCar.html">Customize Neural Network Functional Approximator</a>
    </li>
    <li>
      <a href="../articles/play_atari_games.html">Play Atari Games</a>
    </li>
  </ul>
</li>
<li>
  <a href="../reference/index.html">
    <span class="fa fa-book"></span>
     
    Reference
  </a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/smilesun/rlR">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Define custom environment for deep reinforcement learn</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/smilesun/rlR/blob/master/vignettes/define_custom_environments.Rmd"><code>vignettes/define_custom_environments.Rmd</code></a></small>
      <div class="hidden name"><code>define_custom_environments.Rmd</code></div>

    </div>

    
    
<div id="rlr-define-custom-environments-for-deep-reinforcement-learning-in-r" class="section level1">
<h1 class="hasAnchor">
<a href="#rlr-define-custom-environments-for-deep-reinforcement-learning-in-r" class="anchor"></a>rlR: Define custom environments for Deep Reinforcement learning in R</h1>
<div id="environment-class" class="section level2">
<h2 class="hasAnchor">
<a href="#environment-class" class="anchor"></a>Environment class</h2>
<p>If you want to use this package for your self defined task, you need to implement your own R6 class to represent the environment which must inherit the <code><a href="../reference/Environment.html">rlR::Environment</a></code> Class. You could define other public and private members as you like which do not collide with the names in <code><a href="../reference/Environment.html">rlR::Environment</a></code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rlR)
<span class="kw">library</span>(R6)
<span class="kw">help</span>(<span class="dt">topic=</span><span class="st">"Environment"</span>, <span class="dt">package =</span> <span class="st">"rlR"</span>)
MyEnv =<span class="st"> </span>R6<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/R6/topics/R6Class">R6Class</a></span>(<span class="st">"MyEnv"</span>,
  <span class="dt">inherit =</span> rlR<span class="op">::</span>Environment,
  <span class="dt">public =</span> <span class="kw">list</span>(
    <span class="dt">step_cnt =</span> <span class="ot">NULL</span>,  <span class="co"># a variable that base class does not have</span>
    <span class="dt">s_r_d_info =</span> <span class="ot">NULL</span>,
    <span class="dt">initialize =</span> <span class="cf">function</span>(<span class="dt">state_dim =</span> <span class="dv">4</span>, <span class="dt">act_cnt =</span> <span class="dv">2</span>) {
      super<span class="op">$</span><span class="kw">initialize</span>()
      self<span class="op">$</span>flag_continous =<span class="st"> </span><span class="ot">FALSE</span>  <span class="co"># non-continuous action</span>
      self<span class="op">$</span>state_dim =<span class="st"> </span>state_dim
      self<span class="op">$</span>act_cnt =<span class="st"> </span>act_cnt
      self<span class="op">$</span>step_cnt =<span class="st"> </span>0L
      self<span class="op">$</span>s_r_d_info =<span class="st"> </span><span class="kw">list</span>(
            <span class="dt">state =</span> <span class="kw">array</span>(<span class="kw">rnorm</span>(self<span class="op">$</span>state_dim), <span class="dt">dim =</span> self<span class="op">$</span>state_dim),
            <span class="dt">reward =</span> <span class="fl">1.0</span>,
            <span class="dt">done =</span> <span class="ot">FALSE</span>,
            <span class="dt">info =</span> <span class="kw">list</span>()
      )
    },

    <span class="dt">render =</span> <span class="cf">function</span>(...) {
      <span class="co"># you could leave this field empty. </span>
    },

    <span class="co"># this function will be called at each step of the learning</span>
    <span class="dt">step =</span> <span class="cf">function</span>(action) {
      <span class="kw">cat</span>(<span class="kw">sprintf</span>(<span class="st">"calling step %s"</span>, self<span class="op">$</span>step_cnt))
      self<span class="op">$</span>step_cnt =<span class="st"> </span>self<span class="op">$</span>step_cnt <span class="op">+</span><span class="st"> </span>1L
      <span class="cf">if</span>(self<span class="op">$</span>step_cnt <span class="op">&gt;</span><span class="st"> </span>5L) {
        self<span class="op">$</span>s_r_d_info[[<span class="st">"done"</span>]] =<span class="st"> </span><span class="ot">TRUE</span>
        <span class="kw">cat</span>(<span class="kw">sprintf</span>(<span class="st">"</span><span class="ch">\n</span><span class="st"> Episode Over </span><span class="ch">\n</span><span class="st">"</span>))
        <span class="kw">return</span>(self<span class="op">$</span>s_r_d_info)
      }
      <span class="kw">return</span>(self<span class="op">$</span>s_r_d_info)
    },

    <span class="co"># this function will be called at the beginning of the learning and at the end of each episode</span>
    <span class="dt">reset =</span> <span class="cf">function</span>() {
      self<span class="op">$</span>step_cnt =<span class="st"> </span><span class="dv">0</span>
      self<span class="op">$</span>s_r_d_info[[<span class="st">"done"</span>]] =<span class="st"> </span><span class="ot">FALSE</span>
      self<span class="op">$</span>s_r_d_info
    },

    <span class="dt">afterAll =</span> <span class="cf">function</span>() {
      <span class="kw">print</span>(<span class="st">"interaction finished!"</span>)
      <span class="co"># what to do after the whole learning is finished?  could be left empty</span>
    }
  )
)</code></pre></div>
<p>Afterwards you could choose one of the available Agents to learn on this newly defined environments.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">env =<span class="st"> </span>MyEnv<span class="op">$</span><span class="kw">new</span>()
<span class="kw"><a href="../reference/listAvailAgent.html">listAvailAgent</a></span>()
##                name
## 1:         AgentDQN
## 2:        AgentFDQN
## 3:        AgentDDQN
## 4:          AgentPG
## 5:  AgentPGBaseline
## 6: AgentActorCritic
## 7:        AgentDDPG
##                                                       note
## 1:                                         Deep Q learning
## 2:                           Frozen Target Deep Q Learning
## 3:                                   Double Deep QLearning
## 4:                             Policy Gradient Monte Carlo
## 5:                           Policy Gradient with Baseline
## 6:                                     Actor Critic Method
## 7: Deep Deterministic Policy Gradient for Continous Action
conf =<span class="st"> </span><span class="kw"><a href="../reference/getDefaultConf.html">getDefaultConf</a></span>(<span class="st">"AgentDQN"</span>)
agent =<span class="st"> </span><span class="kw"><a href="../reference/initAgent.html">initAgent</a></span>(<span class="st">"AgentDQN"</span>, env, conf)
perf =<span class="st"> </span>agent<span class="op">$</span><span class="kw">learn</span>(<span class="dv">3</span>)
## calling step 0calling step 1calling step 2calling step 3calling step 4calling step 5
##  Episode Over 
## calling step 0calling step 1calling step 2calling step 3calling step 4calling step 5
##  Episode Over 
## calling step 0calling step 1calling step 2calling step 3calling step 4calling step 5
##  Episode Over 
## [1] "interaction finished!"</code></pre></div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li>
<a href="#rlr-define-custom-environments-for-deep-reinforcement-learning-in-r">rlR: Define custom environments for Deep Reinforcement learning in R</a><ul class="nav nav-pills nav-stacked">
<li><a href="#environment-class">Environment class</a></li>
      </ul>
</li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Xudong Sun.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  

  </body>
</html>
